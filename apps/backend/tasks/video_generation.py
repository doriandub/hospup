from celery import current_task
from core.celery_app import celery_app
from core.database import get_db
from models.video import Video
from models.property import Property
from models.user import User
from models.viral_video_template import ViralVideoTemplate
from services.s3_service import s3_service
from sqlalchemy.orm import Session
from sqlalchemy import text
from typing import Dict, Any, List, Optional
import logging
from datetime import datetime
import uuid
import time
import json
import os
import tempfile
import subprocess

logger = logging.getLogger(__name__)

@celery_app.task(bind=True)
def generate_video_from_template(
    self, 
    viral_video_id: str, 
    property_id: str, 
    user_id: str, 
    input_data: str, 
    input_type: str,
    language: str = "en"
) -> Dict[str, Any]:
    """
    Generate a video based on a viral video template and property content
    """
    logger.info(f"ğŸ¬ Task started: video generation for viral_video_id={viral_video_id}")
    
    try:
        # Test: minimal implementation to isolate segfault
        time.sleep(2)  # Simulate work
        logger.info("ğŸ¬ Task completing successfully with minimal implementation")
        
        return {
            "video_id": "test-video-id",
            "video_url": "https://picsum.photos/640/1138.mp4",
            "thumbnail_url": "https://picsum.photos/640/1138",
            "status": "completed",
            "duration": 30.0,
            "clips_matched": 1,
            "clips_total": 1,
            "match_rate": 1.0,
            "generation_method": "minimal_test",
            "viral_template_title": "Test Template"
        }
        
        # Original code temporarily disabled
        """
        # Get database session
        db = next(get_db())
        
        # Create video record
        video_id = str(uuid.uuid4())
        video = Video(
            id=video_id,
            title=f"Generated Video - {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            description=f"AI-generated video based on viral template",
            video_url="",  # Will be updated when generation completes
            status="processing",
            language=language,
            user_id=user_id,
            property_id=property_id,
            source_type=input_type,
            source_data=input_data,
            viral_video_id=viral_video_id,
            generation_job_id=self.request.id
        )
        
        db.add(video)
        db.commit()
        db.refresh(video)
        
        # Update task progress
        current_task.update_state(
            state="PROGRESS",
            meta={
                "stage": "initializing",
                "progress": 10,
                "video_id": video_id
            }
        )
        
        # Get property details
        property_obj = db.query(Property).filter(Property.id == property_id).first()
        if not property_obj:
            raise ValueError(f"Property {property_id} not found")
        
        current_task.update_state(
            state="PROGRESS",
            meta={
                "stage": "analyzing_template",
                "progress": 25,
                "video_id": video_id
            }
        )
        
        # Get viral video template and script
        viral_template = db.query(ViralVideoTemplate).filter(
            ViralVideoTemplate.id == viral_video_id
        ).first()
        
        if not viral_template or not viral_template.script:
            logger.error(f"No script found for viral template {viral_video_id}")
            raise ValueError(f"No script found for viral template {viral_video_id}")
        
        current_task.update_state(
            state="PROGRESS",
            meta={
                "stage": "analyzing_content_library",
                "progress": 30,
                "video_id": video_id
            }
        )
        
        # Parse input data to check for timeline overrides
        timeline_data = None
        try:
            if input_data and input_data.strip():
                timeline_data = json.loads(input_data)
                logger.info(f"ğŸ“‹ Timeline data received: {timeline_data}")
        except json.JSONDecodeError as e:
            logger.warning(f"Could not parse input_data as JSON: {e}")
            timeline_data = None
        
        # Check if we have timeline slot assignments to override the viral template
        if timeline_data and timeline_data.get("slot_assignments"):
            logger.info("ğŸ¯ Using timeline slot assignments instead of viral template script")
            slot_assignments = timeline_data["slot_assignments"]
            clips = []
            texts = timeline_data.get("text_overlays", [])
            
            # Convert slot assignments to clip format
            for slot in slot_assignments:
                if slot.get("assignedVideo"):
                    clips.append({
                        "order": slot.get("order", len(clips) + 1),
                        "duration": slot.get("duration", 3.0),
                        "description": slot.get("description", ""),
                        "assigned_video_id": slot["assignedVideo"]["id"],
                        "start_time": slot.get("startTime", 0),
                        "end_time": slot.get("endTime", slot.get("duration", 3.0))
                    })
        else:
            # Fallback to viral video script
            logger.info("ğŸ“ Using viral template script (no timeline overrides)")
            try:
                # Clean the script - remove leading = if present
                clean_script = viral_template.script.strip()
                if clean_script.startswith('='):
                    clean_script = clean_script[1:]
                
                script_data = json.loads(clean_script)
                clips = script_data.get("clips", [])
                texts = script_data.get("texts", [])
            except json.JSONDecodeError as e:
                logger.error(f"Error parsing viral script JSON: {e}")
                raise ValueError(f"Invalid script format for viral template {viral_video_id}")
        
        # Get property's uploaded videos for matching
        content_videos = db.query(Video).filter(
            Video.property_id == property_id,
            Video.status == "uploaded"
        ).all()
        
        logger.info(f"ğŸ¬ Processing viral template '{viral_template.title}' with {len(clips)} clips")
        logger.info(f"ğŸ“š Found {len(content_videos)} videos in Content Library for matching")
        
        # Create segments from content videos
        content_segments = []
        for content_video in content_videos:
            # Create enhanced descriptions for better matching
            if content_video.description and content_video.description.strip():
                # Use existing description if available
                description = content_video.description
            else:
                # Create hospitality-focused description from filename
                title = content_video.title or "video"
                if any(word in title.lower() for word in ['pool', 'swim']):
                    description = "Hotel swimming pool area with water, poolside amenities, lounge chairs, and outdoor relaxation space"
                elif any(word in title.lower() for word in ['room', 'bed', 'suite']):
                    description = "Hotel room interior with bed, furniture, window view, and comfortable accommodation space"
                elif any(word in title.lower() for word in ['restaurant', 'dining', 'food']):
                    description = "Hotel restaurant and dining area with food, tables, kitchen, and culinary experience"
                elif any(word in title.lower() for word in ['lobby', 'reception', 'entrance']):
                    description = "Hotel lobby and reception area with front desk, seating, and welcoming entrance space"
                elif any(word in title.lower() for word in ['spa', 'wellness', 'massage']):
                    description = "Hotel spa and wellness center with relaxation, treatment rooms, and wellness amenities"
                elif any(word in title.lower() for word in ['garden', 'outdoor', 'terrace']):
                    description = "Hotel outdoor area with garden, terrace, natural landscape, and outdoor hospitality space"
                elif any(word in title.lower() for word in ['view', 'landscape', 'scenic']):
                    description = "Hotel scenic view with beautiful landscape, panoramic vista, and picturesque surroundings"
                else:
                    # Generic hotel content description with hospitality keywords
                    description = "Hotel hospitality content featuring luxury accommodation, guest amenities, beautiful interior design, comfortable spaces, premium service, and exceptional guest experience"
            
            fake_segment = type('FakeSegment', (), {
                'video_id': content_video.id,
                'start_time': 0.0,
                'end_time': content_video.duration or 10.0,
                'description': description,
                'id': f"fake_{content_video.id}"
            })()
            content_segments.append(fake_segment)
        
        current_task.update_state(
            state="PROGRESS",
            meta={
                "stage": "matching_clips",
                "progress": 50,
                "video_id": video_id
            }
        )
        
        # Match clips to content library (handle both timeline assignments and AI matching)
        matched_segments = []
        for clip in clips:
            clip_description = clip.get("description", "")
            clip_duration = clip.get("duration", 3.0)
            
            # Check if this clip has a specific video assignment from timeline
            if clip.get("assigned_video_id"):
                logger.info(f"ğŸ¯ Using timeline assignment for clip: {clip_description[:50]}...")
                assigned_video_id = clip["assigned_video_id"]
                
                # Find the assigned video in content_segments
                assigned_segment = None
                for segment in content_segments:
                    if segment.video_id == assigned_video_id:
                        assigned_segment = segment
                        break
                
                if assigned_segment:
                    # Use timeline specified start/end times if available
                    if clip.get("start_time") is not None and clip.get("end_time") is not None:
                        extract_start = clip["start_time"]
                        extract_end = clip["end_time"]
                    else:
                        # Use clip duration from the beginning of the segment
                        segment_duration = assigned_segment.end_time - assigned_segment.start_time
                        if segment_duration >= clip_duration:
                            extract_start = assigned_segment.start_time
                            extract_end = assigned_segment.start_time + clip_duration
                        else:
                            extract_start = assigned_segment.start_time
                            extract_end = assigned_segment.end_time
                    
                    matched_segments.append({
                        "viral_clip": clip,
                        "matched_segment": assigned_segment,
                        "extract_start": extract_start,
                        "extract_end": extract_end,
                        "similarity_score": 1.0,  # Perfect match since it's manually assigned
                        "source_video_id": assigned_segment.video_id
                    })
                    
                    logger.info(f"âœ… Timeline assignment: clip '{clip_description[:50]}...' â†’ video {assigned_video_id}")
                else:
                    logger.warning(f"âš ï¸ Assigned video {assigned_video_id} not found in content library")
            else:
                # AI-powered matching for clips without specific assignments
                best_match = None
                best_score = 0
                
                for segment in content_segments:
                    score = _calculate_description_similarity(clip_description, segment.description)
                    if score > best_score:
                        best_score = score
                        best_match = segment
                
                if best_match and best_score > 0.1:
                    segment_duration = best_match.end_time - best_match.start_time
                    if segment_duration >= clip_duration:
                        extract_start = best_match.start_time
                        extract_end = best_match.start_time + clip_duration
                    else:
                        extract_start = best_match.start_time
                        extract_end = best_match.end_time
                    
                    matched_segments.append({
                        "viral_clip": clip,
                        "matched_segment": best_match,
                        "extract_start": extract_start,
                        "extract_end": extract_end,
                        "similarity_score": best_score,
                        "source_video_id": best_match.video_id
                    })
                    
                    logger.info(f"ğŸ¯ AI match: clip '{clip_description[:50]}...' â†’ segment '{best_match.description[:50]}...' (score: {best_score:.2f})")
        
        logger.info(f"ğŸ”— Successfully matched {len(matched_segments)}/{len(clips)} viral clips")
        
        # ğŸ”„ FALLBACK MATCHING: If we have few or no matches, create fallback assignments
        logger.info(f"ğŸ”„ Checking fallback condition: {len(matched_segments)} < {max(1, len(clips) // 2)} = {len(matched_segments) < max(1, len(clips) // 2)}")
        if len(matched_segments) < max(1, len(clips) // 2):  # If we matched less than half the clips
            logger.info(f"ğŸ”„ Low match rate detected ({len(matched_segments)}/{len(clips)}), applying fallback matching...")
            
            # Get unmatched clips
            matched_clip_indices = {match["viral_clip"]["order"] - 1 for match in matched_segments}
            unmatched_clips = [clip for i, clip in enumerate(clips) if i not in matched_clip_indices]
            
            # Assign unmatched clips to available content segments in round-robin fashion
            if content_segments and unmatched_clips:
                logger.info(f"ğŸ¯ Assigning {len(unmatched_clips)} unmatched clips to {len(content_segments)} available segments...")
                
                for i, clip in enumerate(unmatched_clips):
                    # Use round-robin to distribute clips across available segments
                    segment = content_segments[i % len(content_segments)]
                    clip_duration = clip.get("duration", 3.0)
                    
                    # Calculate segment extraction
                    segment_duration = segment.end_time - segment.start_time
                    if segment_duration >= clip_duration:
                        extract_start = segment.start_time
                        extract_end = segment.start_time + clip_duration
                    else:
                        extract_start = segment.start_time
                        extract_end = segment.end_time
                    
                    # Add fallback match
                    matched_segments.append({
                        "viral_clip": clip,
                        "matched_segment": segment,
                        "extract_start": extract_start,
                        "extract_end": extract_end,
                        "similarity_score": 0.05,  # Low score to indicate fallback
                        "source_video_id": segment.video_id
                    })
                    
                    logger.info(f"ğŸ”„ Fallback match: clip '{clip.get('description', '')[:50]}...' â†’ segment '{segment.description[:50]}...'")
            
            logger.info(f"âœ… After fallback: {len(matched_segments)}/{len(clips)} clips now have segments assigned")
        
        current_task.update_state(
            state="PROGRESS",
            meta={
                "stage": "generating_video",
                "progress": 70,
                "video_id": video_id
            }
        )
        
        # Adapt texts to property
        adapted_texts = []
        if texts:
            for text_item in texts:
                original_text = text_item.get("content", "")
                adapted_text = original_text.replace("Paradise Found", f"{property_obj.name} Paradise")
                adapted_text = adapted_text.replace("Dream Escape", f"Your {property_obj.city} Escape")  
                adapted_text = adapted_text.replace("Book Now", f"Book {property_obj.name}")
                
                adapted_texts.append({
                    "original": original_text,
                    "adapted": adapted_text,
                    "start_time": text_item.get("start_time", 0)
                })
        
        # Generate real video using FFmpeg and matched segments
        logger.info(f"ğŸ” Final check: {len(matched_segments)} matched segments ready for video generation")
        
        # Only fail if we STILL have no segments after fallback matching
        if not matched_segments:
            logger.error("No matched segments found even after fallback matching")
            # Mark video as failed and return early
            video.status = "failed"
            db.commit()
            raise ValueError("No matching content found in Content Library")
        
        # Limit segments to prevent memory issues
        if len(matched_segments) > 10:
            logger.warning(f"Too many segments ({len(matched_segments)}), limiting to 10 to prevent memory issues")
            matched_segments = matched_segments[:10]
            
        real_duration = float(viral_template.duration) if viral_template.duration else 30.0
        
        # Temporary: Skip actual video generation to avoid segfault
        logger.info("ğŸ”§ TEMPORARY: Skipping actual video generation to avoid segfault")
        video_url = "https://picsum.photos/640/1138.mp4"  # Placeholder video
        thumbnail_url = "https://picsum.photos/640/1138"  # Placeholder thumbnail
        
        # video_url, thumbnail_url = _generate_video_from_segments(
        #     matched_segments, 
        #     real_duration, 
        #     adapted_texts, 
        #     property_obj,
        #     video_id,
        #     db
        # )
        
        if not video_url:
            logger.error("Failed to generate video using FFmpeg")
            raise ValueError("Video generation failed")
        
        current_task.update_state(
            state="PROGRESS",
            meta={
                "stage": "finalizing",
                "progress": 95,
                "video_id": video_id
            }
        )
        
        # Update video record
        video.video_url = video_url
        video.thumbnail_url = thumbnail_url
        video.status = "completed"
        video.completed_at = datetime.utcnow()
        video.duration = real_duration
        video.size = int(real_duration * 500000)  # Estimate based on quality
        
        # Store generation metadata
        generation_metadata = {
            "viral_template_id": viral_video_id,
            "viral_template_title": viral_template.title,
            "clips_total": len(clips),
            "clips_matched": len(matched_segments),
            "match_rate": len(matched_segments) / len(clips) if clips else 0,
            "content_videos_used": len(content_videos),
            "adapted_texts": adapted_texts,
            "generation_method": "ffmpeg_real_segments",
            "s3_key": f"generated-videos/{property_obj.id}/{video_id}.mp4"
        }
        
        video.source_data = json.dumps(generation_metadata)
        
        db.commit()
        
        # Send WebSocket notification
        try:
            from core.websocket import notify_video_generated
            asyncio.create_task(notify_video_generated(
                user_id=user_id,
                video_data={
                    "video_id": video_id,
                    "title": video.title,
                    "video_url": video_url,
                    "thumbnail_url": thumbnail_url,
                    "job_id": self.request.id
                }
            ))
        except Exception as e:
            logger.warning(f"Failed to send WebSocket notification: {e}")
        
        current_task.update_state(
            state="PROGRESS",
            meta={
                "stage": "completed",
                "progress": 100,
                "video_id": video_id
            }
        )
        
        return {
            "video_id": video_id,
            "video_url": video_url,
            "thumbnail_url": thumbnail_url,
            "status": "completed",
            "duration": real_duration,
            "clips_matched": len(matched_segments),
            "clips_total": len(clips),
            "match_rate": len(matched_segments) / len(clips) if clips else 0,
            "generation_method": "ffmpeg_real_segments",
            "viral_template_title": viral_template.title
        }
        
        """
        
    except Exception as e:
        logger.error(f"Error in minimal video generation task: {str(e)}")
        raise

def _calculate_description_similarity(desc1: str, desc2: str) -> float:
    """Calculate similarity between two descriptions using keyword matching"""
    if not desc1 or not desc2:
        return 0.0
    
    words1 = set(desc1.lower().split())
    words2 = set(desc2.lower().split())
    
    stop_words = {"a", "an", "the", "is", "are", "with", "of", "in", "on", "at", "to", "for", "and", "or"}
    words1 = words1 - stop_words  
    words2 = words2 - stop_words
    
    if not words1 or not words2:
        return 0.0
    
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    jaccard_score = intersection / union if union > 0 else 0.0
    
    # Boost for hospitality-specific keywords
    hospitality_keywords = {
        "pool", "swimming", "water", "beach", "ocean", "spa", "massage", "restaurant", 
        "dining", "food", "cocktail", "drink", "hotel", "room", "bed", "lobby", 
        "garden", "terrace", "view", "sunset", "breakfast", "luxury", "relaxation"
    }
    
    hospitality_matches = len(words1.intersection(words2).intersection(hospitality_keywords))
    hospitality_boost = min(0.3, hospitality_matches * 0.1)
    
    final_score = min(1.0, jaccard_score + hospitality_boost)
    return final_score

def _generate_video_from_segments(matched_segments: List[Dict], target_duration: float, 
                                adapted_texts: List[Dict], property_details, video_id: str, 
                                db: Session) -> tuple[Optional[str], Optional[str]]:
    """Generate video using FFmpeg from matched Content Library segments"""
    try:
        logger.info(f"ğŸ¬ Starting FFmpeg video generation for {len(matched_segments)} segments")
        
        # Create temporary directory for video processing
        temp_dir = tempfile.mkdtemp(prefix=f"video_gen_{video_id}_")
        logger.info(f"ğŸ“ Created temp directory: {temp_dir}")
        
        # Download source videos from S3 and extract segments
        segment_files = []
        
        
        for i, match_data in enumerate(matched_segments):
            try:
                logger.info(f"ğŸ¬ Processing segment {i+1}/{len(matched_segments)}")
                segment = match_data["matched_segment"]
                clip_info = match_data["viral_clip"]
                source_video_id = match_data["source_video_id"]
                
                # Get source video info
                source_video = db.query(Video).filter(Video.id == source_video_id).first()
                if not source_video:
                    logger.warning(f"âš ï¸ Source video {source_video_id} not found")
                    continue
                
                logger.info(f"ğŸ“¹ Processing video: {source_video.title} (duration: {source_video.duration}s)")
                
                # Skip videos that are too short or problematic
                if source_video.duration and source_video.duration < 0.5:
                    logger.warning(f"âš ï¸ Skipping video {source_video.title} - too short ({source_video.duration}s)")
                    continue
                
                # Extract S3 key from video_url
                if source_video.video_url.startswith("s3://"):
                    s3_key = source_video.video_url[5:].split("/", 1)[1]  # Remove s3://bucket_name/
                else:
                    logger.warning(f"âš ï¸ Invalid video URL format: {source_video.video_url}")
                    continue
                
                # Download source video
                local_video_path = os.path.join(temp_dir, f"source_{i}.mp4")
                download_url = s3_service.generate_presigned_download_url(s3_key)
                
                # Download with curl (with timeout)
                download_cmd = ["curl", "-s", "--max-time", "30", "-o", local_video_path, download_url]
                try:
                    result = subprocess.run(download_cmd, capture_output=True, text=True, timeout=60)
                except subprocess.TimeoutExpired:
                    logger.error(f"âŒ Download timeout for video {source_video_id}")
                    continue
                
                if result.returncode != 0:
                    logger.error(f"âŒ Failed to download video {source_video_id}: {result.stderr}")
                    continue
                
                # Verify file was downloaded
                if not os.path.exists(local_video_path) or os.path.getsize(local_video_path) == 0:
                    logger.error(f"âŒ Downloaded video file is empty or missing: {local_video_path}")
                    continue
                
                # Verify video file is valid with ffprobe
                probe_cmd = ["ffprobe", "-v", "quiet", "-show_format", "-show_streams", local_video_path]
                try:
                    probe_result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=10)
                except subprocess.TimeoutExpired:
                    logger.error(f"âŒ FFprobe timeout for video {source_video_id}")
                    os.remove(local_video_path)
                    continue
                
                if probe_result.returncode != 0:
                    logger.error(f"âŒ Video file is corrupted or invalid: {source_video_id}")
                    os.remove(local_video_path)
                    continue
                
                # Extract segment using FFmpeg
                start_time = match_data["extract_start"]
                end_time = match_data["extract_end"]
                duration = end_time - start_time
                
                segment_file = os.path.join(temp_dir, f"segment_{i}.mp4")
                
                ffmpeg_cmd = [
                    "ffmpeg", "-y", "-i", local_video_path,
                    "-ss", str(start_time), "-t", str(duration),
                    "-c", "copy", "-avoid_negative_ts", "make_zero",
                    segment_file
                ]
                
                try:
                    result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True, timeout=30)
                except subprocess.TimeoutExpired:
                    logger.error(f"âŒ FFmpeg timeout for segment {i}")
                    continue
                
                if result.returncode == 0 and os.path.exists(segment_file):
                    segment_files.append(segment_file)
                    logger.info(f"âœ… Extracted segment {i+1}: {duration:.1f}s from {source_video.title}")
                else:
                    logger.error(f"âŒ FFmpeg segment extraction failed: {result.stderr}")
                
                # Clean up source video file
                try:
                    os.remove(local_video_path)
                except:
                    pass
                    
            except Exception as e:
                logger.error(f"âŒ Error processing segment {i}: {e}")
                continue
        
        if not segment_files:
            logger.error("âŒ No valid segments extracted")
            return None, None
        
        logger.info(f"ğŸ¬ Successfully extracted {len(segment_files)} video segments")
        
        # Create final video by concatenating segments
        final_video_path = os.path.join(temp_dir, f"final_video_{video_id}.mp4")
        
        if len(segment_files) == 1:
            # Single segment - just copy
            import shutil
            shutil.copy2(segment_files[0], final_video_path)
        else:
            # Multiple segments - concatenate
            concat_list_path = os.path.join(temp_dir, "concat_list.txt")
            with open(concat_list_path, 'w') as f:
                for segment_file in segment_files:
                    f.write(f"file '{segment_file}'\n")
            
            concat_cmd = [
                "ffmpeg", "-y", "-f", "concat", "-safe", "0", 
                "-i", concat_list_path, "-c", "copy", final_video_path
            ]
            
            try:
                result = subprocess.run(concat_cmd, capture_output=True, text=True, timeout=60)
            except subprocess.TimeoutExpired:
                logger.error("âŒ Video concatenation timeout")
                return None, None
            
            if result.returncode != 0:
                logger.error(f"âŒ Video concatenation failed: {result.stderr}")
                return None, None
        
        # Verify final video exists
        if not os.path.exists(final_video_path):
            logger.error("âŒ Final video file not created")
            return None, None
        
        logger.info(f"ğŸ¬ Final video created: {final_video_path}")
        
        # Upload to S3
        s3_key = f"generated-videos/{property_details.id}/{video_id}.mp4"
        
        with open(final_video_path, 'rb') as video_file:
            upload_result = s3_service.upload_file_direct(
                video_file, s3_key, content_type="video/mp4", public_read=False
            )
        
        if upload_result.get('success'):
            # Generate presigned URL that expires in 24 hours
            video_url = s3_service.generate_presigned_download_url(s3_key, expires_in=86400)
            thumbnail_url = "https://picsum.photos/640/1138"  # Placeholder thumbnail
            
            logger.info(f"âœ… Video uploaded successfully with presigned URL")
            return video_url, thumbnail_url
        else:
            logger.error("âŒ S3 upload failed")
            return None, None
            
    except Exception as e:
        logger.error(f"âŒ Video generation error: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None, None
    finally:
        # Cleanup temporary files
        try:
            import shutil
            shutil.rmtree(temp_dir)
            logger.info("ğŸ§¹ Cleaned up temporary files")
        except Exception as e:
            logger.warning(f"âš ï¸ Cleanup failed: {e}")

def generate_video_script(viral_video_id: str, property_obj: Property, input_data: str, language: str) -> str:
    """
    Generate a video script based on the viral template and property details
    """
    # This would integrate with OpenAI GPT to generate the script
    # For now, return a mock script
    
    script = f"""
VIRAL VIDEO SCRIPT FOR {property_obj.name}

Location: {property_obj.city}, {property_obj.country}
Type: {property_obj.property_type.replace('_', ' ').title()}
Language: {language}

SCENE 1: Opening Hook (0-3s)
- Quick establishing shot of {property_obj.name}
- Text overlay: "You won't believe this {property_obj.property_type}..."

SCENE 2: Main Content (3-20s)
- Showcase based on input: {input_data}
- Highlight unique features of the property
- Dynamic transitions and trending music

SCENE 3: Call to Action (20-30s)
- Contact information
- Location details: {property_obj.city}
- Booking call-to-action

Music: Trending TikTok audio
Style: Quick cuts, engaging transitions
Hashtags: #{property_obj.property_type} #{property_obj.city.lower()} #viral
"""
    
    return script

@celery_app.task(bind=True)
def check_generation_status(self, job_id: str) -> Dict[str, Any]:
    """
    Check the status of a video generation job
    """
    try:
        # Get the task result
        result = celery_app.AsyncResult(job_id)
        
        return {
            "job_id": job_id,
            "status": result.state,
            "result": result.result if result.ready() else None,
            "info": result.info
        }
    except Exception as e:
        logger.error(f"Error checking generation status: {str(e)}")
        return {
            "job_id": job_id,
            "status": "FAILURE",
            "error": str(e)
        }