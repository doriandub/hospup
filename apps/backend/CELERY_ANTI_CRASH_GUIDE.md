# ğŸ›¡ï¸ Guide Anti-Crash Celery Workers

## ProblÃ¨me rÃ©solu : Crashes SIGSEGV rÃ©currents

Les workers Celery crashaient constamment avec des erreurs SIGSEGV (signal 11), causant des blocages de gÃ©nÃ©ration vidÃ©o. Ce guide prÃ©sente la solution complÃ¨te et permanente.

## ğŸ” Causes identifiÃ©es des crashes SIGSEGV

1. **CompatibilitÃ© Python 3.13 + ARM64** - Version rÃ©cente avec problÃ¨mes de threading
2. **Forks problÃ©matiques** - Pool par dÃ©faut cause des conflits mÃ©moire
3. **Threading non contrÃ´lÃ©** - OpenCV/FFmpeg avec trop de threads
4. **Fuites mÃ©moire** - Workers qui accumulent de la mÃ©moire
5. **Conflits bibliothÃ¨ques natives** - OpenCV 4.12 + FFmpeg 7.1

## âœ… Solutions implÃ©mentÃ©es

### 1. Configuration Celery optimisÃ©e (`core/celery_app.py`)

```python
# Configuration anti-crash
worker_pool='solo'                    # Ã‰vite les forks
worker_max_tasks_per_child=10         # RedÃ©marrage frÃ©quent  
worker_max_memory_per_child=256000    # Limite mÃ©moire stricte
task_time_limit=15 * 60               # Timeouts rÃ©duits
```

### 2. Initialisation worker avec optimisations

```python
@worker_process_init.connect
def worker_process_init_handler(signal, sender, **kwargs):
    # Threading limitÃ©
    os.environ['OMP_NUM_THREADS'] = '1'
    cv2.setNumThreads(1)
    
    # Limite mÃ©moire processus
    resource.setrlimit(resource.RLIMIT_AS, (1GB, 1GB))
```

### 3. Scripts de lancement sÃ©curisÃ©s

- **`start_celery_stable.sh`** - Script interactif avec choix de mode
- **`scripts/celery_supervisor.py`** - Superviseur auto-restart

## ğŸš€ Utilisation

### Option 1: Script interactif (RecommandÃ©)
```bash
cd apps/backend
./start_celery_stable.sh
```

**Modes disponibles:**
1. Worker seul (idÃ©al pour tests)
2. Worker + Beat (production complÃ¨te)  
3. Superviseur automatique (redÃ©marrage auto)

### Option 2: Commande directe optimisÃ©e
```bash
cd apps/backend
source venv/bin/activate

# Variables d'environnement anti-crash
export OMP_NUM_THREADS=1
export OPENCV_IO_MAX_IMAGE_PIXELS=100000000
export MALLOC_ARENA_MAX=2

# Lancement worker stable
celery -A core.celery_app worker \
  --pool=solo \
  --concurrency=1 \
  --max-tasks-per-child=10 \
  --max-memory-per-child=256000 \
  --time-limit=900 \
  --without-gossip \
  --without-mingle \
  --without-heartbeat
```

### Option 3: Superviseur automatique
```bash
cd apps/backend
python scripts/celery_supervisor.py
```

## ğŸ”§ Configuration des variables d'environnement

Le systÃ¨me configure automatiquement:

```bash
# Threading control
OMP_NUM_THREADS=1
MKL_NUM_THREADS=1  
OPENBLAS_NUM_THREADS=1

# OpenCV stability
OPENCV_IO_MAX_IMAGE_PIXELS=100000000
OPENCV_FFMPEG_CAPTURE_OPTIONS="rtsp_transport;udp"

# Memory management  
MALLOC_ARENA_MAX=2
MALLOC_TRIM_THRESHOLD_=131072

# FFmpeg stability
FFMPEG_HIDE_BANNER=1
AV_LOG_FORCE_NOCOLOR=1
```

## ğŸ¥ SystÃ¨me de surveillance et recovery

### Recovery automatique intÃ©grÃ©
- **FrÃ©quence**: Toutes les 3 minutes  
- **DÃ©tection**: VidÃ©os bloquÃ©es > 5 minutes
- **Action**: Marque comme "failed" pour retry manuel

### Superviseur avancÃ© (`celery_supervisor.py`)
- **Surveillance**: Processus worker en temps rÃ©el
- **DÃ©tection crash**: SIGSEGV, zombies, timeouts
- **RedÃ©marrage**: Automatique avec limites anti-spam
- **Logs**: Complets avec statistiques

### Monitoring en temps rÃ©el
```python
# Stats processus toutes les 2 minutes
worker_stats = {
    'pid': process.pid,
    'cpu_percent': proc.cpu_percent(), 
    'memory_mb': proc.memory_info().rss / 1024 / 1024,
    'num_threads': proc.num_threads()
}
```

## ğŸ“Š MÃ©triques de stabilitÃ©

### Limites de sÃ©curitÃ©
- **Max tÃ¢ches par worker**: 10 (puis redÃ©marrage)
- **Max mÃ©moire par worker**: 256MB
- **Timeout tÃ¢che**: 15 minutes
- **Max redÃ©marrages/heure**: 10

### Pool de workers
- **Type**: `solo` (pas de fork)
- **Concurrency**: 1 (une tÃ¢che Ã  la fois)
- **Prefetch**: 1 (pas de buffer)

## ğŸ” Diagnostic et troubleshooting

### VÃ©rifier l'Ã©tat des workers
```bash
# Processus actifs
ps aux | grep celery

# Logs en temps rÃ©el  
tail -f /tmp/celery_supervisor.log

# Ã‰tat Redis
redis-cli ping
```

### Logs importants
- **Worker init**: `"âœ… Worker process initialized avec optimisations anti-crash"`
- **OpenCV config**: `"âœ… OpenCV configurÃ© en single-thread"`
- **Memory limit**: `"âœ… Limite mÃ©moire processus configurÃ©e (1GB)"`

### En cas de crash persistant
1. VÃ©rifier les logs: `/tmp/celery_supervisor.log`
2. VÃ©rifier Redis: `redis-cli ping`
3. RedÃ©marrer avec superviseur: `python scripts/celery_supervisor.py`

## âš¡ Performance et optimisations

### Avantages de la solution
- âœ… **StabilitÃ©**: Plus de crashes SIGSEGV
- âœ… **Monitoring**: Surveillance temps rÃ©el 
- âœ… **Recovery**: RedÃ©marrage automatique
- âœ… **Performance**: GÃ©nÃ©ration vidÃ©o rapide maintenue
- âœ… **SimplicitÃ©**: Scripts prÃªts Ã  l'emploi

### Trade-offs acceptÃ©s  
- ğŸ”„ RedÃ©marrages plus frÃ©quents (tous les 10 tÃ¢ches)
- ğŸ“‰ Une seule tÃ¢che Ã  la fois par worker
- ğŸ’¾ Limite mÃ©moire stricte (256MB)

## ğŸ¯ RÃ©sultat final

**Avant**: Workers crashaient constamment, gÃ©nÃ©ration vidÃ©o bloquÃ©e
**AprÃ¨s**: Workers stables, gÃ©nÃ©ration vidÃ©o fiable, monitoring complet

La solution garantit un systÃ¨me de gÃ©nÃ©ration vidÃ©o robuste et fiable, avec redÃ©marrage automatique en cas de problÃ¨me.